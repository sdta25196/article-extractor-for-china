# 中文文章提取

## 启动

1. yarn 
2. yarn start

## 特性

* 支持对列表和分页的识别与抓取
* 支持对文章详情页面的抓取
* 针对更多国内网站进行了优化
* 支持 HTML5 标签 ( article, section) 
* 支持GBK、GB2312等编码
* 自动将图像和链接的相对 URL 转换为绝对 URL

## 优化方案 

* 某网站第一次跑了之后，给这个网站一堆标记，然后第二次跑的时候直接根据标记优化即可


## 常见规则

* 视觉分析 - 模拟真实用户，分析字号、字体、颜色信息，最终确定一个区域为内容区。
* 模板配置 - 先确认模板，如果匹配到模板直接按照模板的标准抓取。
  * 规则匹配 - 属于模板的一种，例如指定规则为有time\title\author\content。此时content是正文。
* 关键字匹配 - 正文、content、title等文案或者class。
* 深度学习 - 利用深度学习库，进行训练学习。
* 文本分行后的文本密度 或者 标签密度 进行判断。 
  * 密度判断对短文无效
* 利用分析 + 规则匹配,计算权重重新排列dom, 来获得文章
  * 权重的判定方法决定了最终文章的准确性


本项目采取 利用分析 + 规则匹配,计算权重重新排列dom, 来获得文章。

## 规则

**详情页**

获取正文标题：
  * 提取网页的 title \ .title \ #title \ h1 \ h2

正文内容a标签密度小于 5% （a的文本量 / 全部文本）

正文内容包含大量的标点符号

正文长度大于50

嵌入标签需要分别处理

不同情况处理：
* pdf：需要拿到iframe中的地址，然后拿地址中的全部html进行处理
* js渲染：延迟拿全部html
* 内容是图片：不处理
* 详情页是文件下载
* 网站打不开，https认证不过
  
## TODO

* ~~拆分type~~
* ~~添加encoding 处理不同的编码，gbk、GB2312支持~~
* ~~判断页面是否符合分析逻辑~~
* 入口代码编写
* jsdom 代替linkdom ，获取window, 并且可以执行js
* 列表规则、分页规则
* 301 支持